{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.4691 - loss: 0.7732 - val_accuracy: 0.2000 - val_loss: 0.8173\n",
      "Epoch 2/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4560 - loss: 0.7769 - val_accuracy: 0.3000 - val_loss: 0.8171\n",
      "Epoch 3/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4691 - loss: 0.7615 - val_accuracy: 0.3000 - val_loss: 0.8170\n",
      "Epoch 4/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4623 - loss: 0.7564 - val_accuracy: 0.2000 - val_loss: 0.8171\n",
      "Epoch 5/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4623 - loss: 0.7517 - val_accuracy: 0.2000 - val_loss: 0.8175\n",
      "Epoch 6/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4623 - loss: 0.7471 - val_accuracy: 0.2000 - val_loss: 0.8181\n",
      "Epoch 7/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4623 - loss: 0.7428 - val_accuracy: 0.2000 - val_loss: 0.8189\n",
      "Epoch 8/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4623 - loss: 0.7388 - val_accuracy: 0.2000 - val_loss: 0.8198\n",
      "Epoch 9/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4365 - loss: 0.7349 - val_accuracy: 0.2000 - val_loss: 0.8208\n",
      "Epoch 10/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4365 - loss: 0.7312 - val_accuracy: 0.2000 - val_loss: 0.8218\n",
      "Epoch 11/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4365 - loss: 0.7278 - val_accuracy: 0.2000 - val_loss: 0.8229\n",
      "Epoch 12/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4262 - loss: 0.7246 - val_accuracy: 0.2000 - val_loss: 0.8240\n",
      "Epoch 13/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4304 - loss: 0.7216 - val_accuracy: 0.2000 - val_loss: 0.8252\n",
      "Epoch 14/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4406 - loss: 0.7188 - val_accuracy: 0.2000 - val_loss: 0.8264\n",
      "Epoch 15/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4406 - loss: 0.7162 - val_accuracy: 0.2000 - val_loss: 0.8276\n",
      "Epoch 16/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4437 - loss: 0.7127 - val_accuracy: 0.2000 - val_loss: 0.8289\n",
      "Epoch 17/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4406 - loss: 0.7114 - val_accuracy: 0.2000 - val_loss: 0.8302\n",
      "Epoch 18/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4406 - loss: 0.7091 - val_accuracy: 0.2000 - val_loss: 0.8316\n",
      "Epoch 19/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4406 - loss: 0.7070 - val_accuracy: 0.2000 - val_loss: 0.8331\n",
      "Epoch 20/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4406 - loss: 0.7049 - val_accuracy: 0.2000 - val_loss: 0.8346\n",
      "Epoch 21/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4561 - loss: 0.7029 - val_accuracy: 0.2000 - val_loss: 0.8361\n",
      "Epoch 22/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4561 - loss: 0.7010 - val_accuracy: 0.2000 - val_loss: 0.8378\n",
      "Epoch 23/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4663 - loss: 0.6992 - val_accuracy: 0.2000 - val_loss: 0.8395\n",
      "Epoch 24/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4663 - loss: 0.6975 - val_accuracy: 0.3000 - val_loss: 0.8412\n",
      "Epoch 25/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4731 - loss: 0.6958 - val_accuracy: 0.3000 - val_loss: 0.8429\n",
      "Epoch 26/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4663 - loss: 0.6943 - val_accuracy: 0.3000 - val_loss: 0.8447\n",
      "Epoch 27/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4818 - loss: 0.6928 - val_accuracy: 0.3000 - val_loss: 0.8466\n",
      "Epoch 28/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4818 - loss: 0.6914 - val_accuracy: 0.3000 - val_loss: 0.8484\n",
      "Epoch 29/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4920 - loss: 0.6901 - val_accuracy: 0.3000 - val_loss: 0.8502\n",
      "Epoch 30/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4949 - loss: 0.6876 - val_accuracy: 0.3000 - val_loss: 0.8521\n",
      "Epoch 31/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5179 - loss: 0.6876 - val_accuracy: 0.3000 - val_loss: 0.8540\n",
      "Epoch 32/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5220 - loss: 0.6864 - val_accuracy: 0.3000 - val_loss: 0.8559\n",
      "Epoch 33/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5375 - loss: 0.6853 - val_accuracy: 0.3000 - val_loss: 0.8577\n",
      "Epoch 34/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5375 - loss: 0.6841 - val_accuracy: 0.3000 - val_loss: 0.8596\n",
      "Epoch 35/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5375 - loss: 0.6830 - val_accuracy: 0.3000 - val_loss: 0.8615\n",
      "Epoch 36/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5632 - loss: 0.6819 - val_accuracy: 0.3000 - val_loss: 0.8634\n",
      "Epoch 37/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5700 - loss: 0.6808 - val_accuracy: 0.3000 - val_loss: 0.8653\n",
      "Epoch 38/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5700 - loss: 0.6796 - val_accuracy: 0.3000 - val_loss: 0.8670\n",
      "Epoch 39/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5700 - loss: 0.6785 - val_accuracy: 0.3000 - val_loss: 0.8687\n",
      "Epoch 40/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5835 - loss: 0.6774 - val_accuracy: 0.3000 - val_loss: 0.8703\n",
      "Epoch 41/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5835 - loss: 0.6763 - val_accuracy: 0.4000 - val_loss: 0.8717\n",
      "Epoch 42/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5835 - loss: 0.6752 - val_accuracy: 0.4000 - val_loss: 0.8730\n",
      "Epoch 43/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5876 - loss: 0.6728 - val_accuracy: 0.4000 - val_loss: 0.8742\n",
      "Epoch 44/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5865 - loss: 0.6736 - val_accuracy: 0.4000 - val_loss: 0.8754\n",
      "Epoch 45/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5767 - loss: 0.6720 - val_accuracy: 0.4000 - val_loss: 0.8767\n",
      "Epoch 46/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5767 - loss: 0.6709 - val_accuracy: 0.3000 - val_loss: 0.8781\n",
      "Epoch 47/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5767 - loss: 0.6700 - val_accuracy: 0.3000 - val_loss: 0.8795\n",
      "Epoch 48/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5767 - loss: 0.6690 - val_accuracy: 0.3000 - val_loss: 0.8807\n",
      "Epoch 49/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5767 - loss: 0.6681 - val_accuracy: 0.3000 - val_loss: 0.8820\n",
      "Epoch 50/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5767 - loss: 0.6671 - val_accuracy: 0.2000 - val_loss: 0.8833\n",
      "Epoch 51/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5802 - loss: 0.6662 - val_accuracy: 0.2000 - val_loss: 0.8846\n",
      "Epoch 52/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6061 - loss: 0.6653 - val_accuracy: 0.2000 - val_loss: 0.8857\n",
      "Epoch 53/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6019 - loss: 0.6644 - val_accuracy: 0.2000 - val_loss: 0.8867\n",
      "Epoch 54/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6087 - loss: 0.6636 - val_accuracy: 0.2000 - val_loss: 0.8877\n",
      "Epoch 55/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6128 - loss: 0.6627 - val_accuracy: 0.2000 - val_loss: 0.8886\n",
      "Epoch 56/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6128 - loss: 0.6619 - val_accuracy: 0.2000 - val_loss: 0.8895\n",
      "Epoch 57/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6128 - loss: 0.6610 - val_accuracy: 0.2000 - val_loss: 0.8903\n",
      "Epoch 58/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6438 - loss: 0.6602 - val_accuracy: 0.2000 - val_loss: 0.8910\n",
      "Epoch 59/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6438 - loss: 0.6593 - val_accuracy: 0.2000 - val_loss: 0.8917\n",
      "Epoch 60/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6283 - loss: 0.6584 - val_accuracy: 0.2000 - val_loss: 0.8924\n",
      "Epoch 61/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6283 - loss: 0.6575 - val_accuracy: 0.2000 - val_loss: 0.8930\n",
      "Epoch 62/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6283 - loss: 0.6566 - val_accuracy: 0.2000 - val_loss: 0.8935\n",
      "Epoch 63/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6325 - loss: 0.6557 - val_accuracy: 0.2000 - val_loss: 0.8939\n",
      "Epoch 64/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6479 - loss: 0.6548 - val_accuracy: 0.2000 - val_loss: 0.8943\n",
      "Epoch 65/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6469 - loss: 0.6541 - val_accuracy: 0.2000 - val_loss: 0.8945\n",
      "Epoch 66/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6479 - loss: 0.6530 - val_accuracy: 0.2000 - val_loss: 0.8946\n",
      "Epoch 67/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6479 - loss: 0.6521 - val_accuracy: 0.2000 - val_loss: 0.8947\n",
      "Epoch 68/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6325 - loss: 0.6512 - val_accuracy: 0.2000 - val_loss: 0.8947\n",
      "Epoch 69/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6427 - loss: 0.6504 - val_accuracy: 0.2000 - val_loss: 0.8947\n",
      "Epoch 70/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6427 - loss: 0.6496 - val_accuracy: 0.2000 - val_loss: 0.8946\n",
      "Epoch 71/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6427 - loss: 0.6488 - val_accuracy: 0.2000 - val_loss: 0.8945\n",
      "Epoch 72/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6427 - loss: 0.6479 - val_accuracy: 0.2000 - val_loss: 0.8944\n",
      "Epoch 73/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6530 - loss: 0.6471 - val_accuracy: 0.2000 - val_loss: 0.8943\n",
      "Epoch 74/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6530 - loss: 0.6462 - val_accuracy: 0.2000 - val_loss: 0.8942\n",
      "Epoch 75/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6530 - loss: 0.6454 - val_accuracy: 0.2000 - val_loss: 0.8940\n",
      "Epoch 76/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6530 - loss: 0.6445 - val_accuracy: 0.2000 - val_loss: 0.8938\n",
      "Epoch 77/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6530 - loss: 0.6437 - val_accuracy: 0.2000 - val_loss: 0.8936\n",
      "Epoch 78/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6530 - loss: 0.6428 - val_accuracy: 0.2000 - val_loss: 0.8934\n",
      "Epoch 79/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6542 - loss: 0.6419 - val_accuracy: 0.3000 - val_loss: 0.8932\n",
      "Epoch 80/80\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6530 - loss: 0.6411 - val_accuracy: 0.3000 - val_loss: 0.8929\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.7596\n",
      "Test Loss: 0.7596117258071899\n",
      "Test Accuracy: 0.5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "Predictions: [[0.6898567 ]\n",
      " [0.54008055]\n",
      " [0.442137  ]\n",
      " [0.51716346]\n",
      " [0.38931555]\n",
      " [0.45086268]\n",
      " [0.38881594]\n",
      " [0.38055983]\n",
      " [0.4034344 ]\n",
      " [0.50770724]]\n",
      "min: 0.38055983\n",
      "max: 0.6898567\n",
      "mean: 0.47099334\n",
      "shape: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(5,)),  # Input layer with 5 features\n",
    "    Dense(10, activation='relu'),  # Dense layer with 10 neurons and ReLU activation\n",
    "    Dense(1, activation='sigmoid')  # Output layer with 1 neuron (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate synthetic input data (100 samples, 5 features)\n",
    "input_data = np.random.randn(100, 5).astype(np.float32)\n",
    "labels = np.random.randint(0, 2, 100).astype(np.float32)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(input_data, labels, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=16, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Predictions and statistics\n",
    "result = model.predict(X_test[:10])\n",
    "print(\"Predictions:\", result[:10])\n",
    "print(\"min:\", result.min())\n",
    "print(\"max:\", result.max())\n",
    "print(\"mean:\", result.mean())\n",
    "print(\"shape:\", result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.categorical_crossentropy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
